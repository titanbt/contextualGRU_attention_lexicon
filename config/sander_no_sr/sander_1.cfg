# tweets are resolved from sander corpus
# tweets is divided into 3 files (train, dev, test)
# tweets are preprocessed.

[bilstm_cnn]
train_file                      = ./data/sander_no_sr/fold_1/train.txt
dev_file                        = ./data/sander_no_sr/fold_1/dev.txt
test_file                       = ./data/sander_no_sr/fold_1/test.txt
word_column                     = 2
label_column                    = 1
oov                             = embedding
fine_tune                       = True
embedding                       = word2vec
embedding_path                  = ./vec/w2v.bin
use_character                   = True
batch_size                      = 4
num_epochs                      = 30
patience                        = 5
num_units                       = 80
num_filters                     = 6,14
filter_size                     = 7,5
peepholes                       = False
grad_clipping                   = 3
dropout                         = 0.5
regular                         = None
gamma                           = 1e-6
learning_rate                   = 0.1
update_algo                     = adadelta
momentum                        = 0.9
decay_rate                      = 0.1
output_predict                  = True
valid_freq                      = 10
L2                              = 0.0001,0.00003,0.000003,0.0001